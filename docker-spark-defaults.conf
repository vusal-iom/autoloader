# Spark Connect Test Configuration

# Iceberg Catalog
spark.sql.catalog.test_catalog=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.test_catalog.type=hadoop
spark.sql.catalog.test_catalog.warehouse=s3a://test-lakehouse/warehouse

# Iceberg Extensions
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# S3/MinIO Configuration (credentials provided per-session, not cluster-wide)
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=false

# Spark Optimizations
spark.sql.adaptive.enabled=true
spark.sql.sources.default=iceberg

# Heartbeat and Timeout Configuration (generous for Mac sleep/wake cycles)
# Executor heartbeat interval - how often executor sends heartbeat to driver
spark.executor.heartbeatInterval=60s

# Network timeout - RPC communication timeout between driver and executors
spark.network.timeout=600s

# Executor heartbeat timeout - how long driver waits before declaring executor dead (approx 2days)
spark.storage.blockManagerHeartbeatTimeoutMs=200000000

# RPC ask timeout - timeout for RPC requests
spark.rpc.askTimeout=600s

# RPC lookup timeout - timeout for endpoint lookups
spark.rpc.lookupTimeout=600s

# Scheduler revive interval - how often scheduler checks for new tasks
spark.scheduler.revive.interval=10s

# File commit timeout
spark.sql.streaming.fileSource.commitTimeout=600s
